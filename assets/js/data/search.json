[ { "title": "Random SQL Data", "url": "/posts/sql-random-data/", "categories": "howto", "tags": "sql, oracle", "date": "2025-11-19 17:30:00 -0600", "snippet": "Oracle Random Data Generation GuideThis guide explains how to generate random data in Oracle using PL/SQL. It includes: A reusable function generate_random_data for creating random values. A procedure populate_random_data for populating a table with random rows.1. Function: generate_random_dataThis function generates random data based on the specified data type and length.Supported Data Types: NUMBER: Random number with specified length. DATE: Random date within the last 10 years. VARCHAR2: Random string of specified length.Code:CREATE OR REPLACE FUNCTION generate_random_data ( p_length IN NUMBER, p_datatype IN VARCHAR2) RETURN VARCHAR2 IS v_result VARCHAR2(4000);BEGIN CASE UPPER(p_datatype) WHEN &#39;NUMBER&#39; THEN -- Generate a random number with p_length digits v_result := TO_CHAR(TRUNC(DBMS_RANDOM.VALUE(POWER(10, p_length - 1), POWER(10, p_length)))); WHEN &#39;DATE&#39; THEN -- Generate a random date within the last 10 years v_result := TO_CHAR(TRUNC(SYSDATE - DBMS_RANDOM.VALUE(0, 3650)), &#39;DD-MON-YYYY&#39;); WHEN &#39;VARCHAR2&#39; THEN -- Generate a random string of length p_length v_result := DBMS_RANDOM.STRING(&#39;U&#39;, p_length); ELSE RAISE_APPLICATION_ERROR(-20001, &#39;Unsupported data type: &#39; || p_datatype); END CASE; RETURN v_result;END;/Example Usage:SELECT generate_random_data(5, &#39;NUMBER&#39;) FROM dual;SELECT generate_random_data(10, &#39;VARCHAR2&#39;) FROM dual;SELECT generate_random_data(0, &#39;DATE&#39;) FROM dual;2. Procedure: populate_random_dataThis procedure populates a specified table with random data for all its columns.Features: Dynamically reads column metadata. Generates fresh random values for each row. Supports VARCHAR2, NUMBER, and DATE columns.Code:CREATE OR REPLACE PROCEDURE populate_random_data ( p_table_name IN VARCHAR2, p_row_count IN NUMBER) IS v_sql VARCHAR2(32767); v_cols VARCHAR2(32767);BEGIN -- Build column list dynamically FOR col IN ( SELECT column_name, data_type, data_length FROM user_tab_columns WHERE table_name = UPPER(p_table_name) ORDER BY column_id ) LOOP v_cols := v_cols || col.column_name || &#39;, &#39;; END LOOP; v_cols := RTRIM(v_cols, &#39;, &#39;); -- Insert rows FOR i IN 1..p_row_count LOOP DECLARE v_values VARCHAR2(32767); BEGIN -- Generate new random values for each row FOR col IN ( SELECT column_name, data_type, data_length FROM user_tab_columns WHERE table_name = UPPER(p_table_name) ORDER BY column_id ) LOOP IF col.data_type IN (&#39;VARCHAR2&#39;, &#39;CHAR&#39;) THEN v_values := v_values || &#39;&#39;&#39; || generate_random_data(col.data_length, &#39;VARCHAR2&#39;) || &#39;&#39;, &#39;; ELSIF col.data_type = &#39;NUMBER&#39; THEN v_values := v_values || generate_random_data(5, &#39;NUMBER&#39;) || &#39;, &#39;; ELSIF col.data_type = &#39;DATE&#39; THEN v_values := v_values || &#39;TO_DATE(&#39;&#39; || generate_random_data(0, &#39;DATE&#39;) || &#39;&#39;, &#39;&#39;DD-MON-YYYY&#39;&#39;), &#39;; ELSE v_values := v_values || &#39;NULL, &#39;; END IF; END LOOP; v_values := RTRIM(v_values, &#39;, &#39;); v_sql := &#39;INSERT INTO &#39; || p_table_name || &#39; (&#39; || v_cols || &#39;) VALUES (&#39; || v_values || &#39;)&#39;; EXECUTE IMMEDIATE v_sql; END; END LOOP; COMMIT;END;/Example Usage:BEGIN populate_random_data(&#39;EMPLOYEES&#39;, 10);END;/Notes: Ensure the table has no NOT NULL constraints without defaults. Unsupported column types will be set to NULL. You can extend the logic for more data types like CLOB, TIMESTAMP, etc.Tips: Use DBMS_RANDOM.STRING(&#39;A&#39;, length) for mixed case letters. Adjust date range by changing DBMS_RANDOM.VALUE(0, 3650)." }, { "title": "SQL Pagination", "url": "/posts/sql-pagination/", "categories": "howto", "tags": "sql, oracle", "date": "2025-11-17 21:30:00 -0600", "snippet": "SQL Pagination with Materialized View and Pipelined Table Function in OracleOverviewThis guide explains how to implement snapshot-based pagination in Oracle using: A Materialized View (MV) to store a consistent snapshot of the employees table. A pipelined table function to return paginated results as a table type, enabling easy querying with SELECT * FROM TABLE(...).This approach ensures that all pages are based on the same snapshot, even if the underlying employees table changes during pagination.Step 1: Create the Materialized ViewThe MV will hold a static snapshot of the employees table.CREATE MATERIALIZED VIEW mv_employees_snapshotBUILD IMMEDIATEREFRESH ON DEMANDASSELECT employee_id, first_name, last_name, email, hire_dateFROM employeesORDER BY employee_id; REFRESH ON DEMAND: You control when the snapshot updates. ORDER BY employee_id: Ensures stable ordering for pagination.Step 2: Refresh the Materialized ViewBefore starting pagination, refresh the MV to capture the latest data.EXEC DBMS_MVIEW.REFRESH(&#39;MV_EMPLOYEES_SNAPSHOT&#39;, &#39;COMPLETE&#39;);This ensures the MV contains a consistent snapshot of the employees table.Step 3: Create Object and Table TypesDefine an object type for a single row and a table type for multiple rows.CREATE OR REPLACE TYPE employee_obj AS OBJECT ( employee_id NUMBER, first_name VARCHAR2(50), last_name VARCHAR2(50), email VARCHAR2(100), hire_date DATE);CREATE OR REPLACE TYPE employee_tab AS TABLE OF employee_obj;Step 4: Create the Pipelined Table FunctionThis function reads from the MV and returns paginated rows using PIPE ROW.CREATE OR REPLACE FUNCTION get_paginated_mv_pipe ( p_page_number IN NUMBER, p_page_size IN NUMBER) RETURN employee_tab PIPELINEDASBEGIN FOR rec IN ( SELECT employee_id, first_name, last_name, email, hire_date FROM mv_employees_snapshot ORDER BY employee_id OFFSET ((p_page_number - 1) * p_page_size) ROWS FETCH NEXT p_page_size ROWS ONLY ) LOOP PIPE ROW(employee_obj(rec.employee_id, rec.first_name, rec.last_name, rec.email, rec.hire_date)); END LOOP; RETURN;END;/Example UsageQuery the pipelined function like a table:-- Refresh the MV firstEXEC DBMS_MVIEW.REFRESH(&#39;MV_EMPLOYEES_SNAPSHOT&#39;, &#39;COMPLETE&#39;);-- Fetch page 2 with 10 rows per pageSELECT *FROM TABLE(get_paginated_mv_pipe(2, 10));Notes Always refresh the MV before starting pagination to ensure consistency. This approach guarantees a stable snapshot across all pages. For very large datasets, consider indexing the MV for better performance." }, { "title": "Github Actions Deployments", "url": "/posts/github-deployments/", "categories": "howto", "tags": "git", "date": "2025-04-10 02:11:00 -0600", "snippet": "Using Github Actions for DeploymentsSetup Github Actions for DeploymentAction to deploy PRs made against main branch (in my case Development).Action to deploy to QA, Production, etc. after tests pass in Development.Setup Rulesets for enforcement or assistance in following processesRuleset on Development to Require a PR, and code review. Target branches: Development Restrict deletions Require a pull request before merging Require Approvals: 1 Block force pushesRuleset for Deploying Tags Target tags: *-Deploy-QA, *=Deploy-PROD Restrict updates - we don’t want changes after a deployment. Raise a new tag. Restrict deletions - we want to maintain a nice history for audits. Block force pushesRuleset for Tag Naming (just to avoid typos) Target tags excluding: *-Deploy-QA, *-Deploy-PROD Restrict creations Block force pushesSetup Environments for Deployments PROD, QA environments with Required reviewers: DBA team. Allows DBA team to control when changes get deployed. Development environment could be setup with Required reviewers: Developers. This would serve as a peer review. This is already handled by the PR ruleset, so only choose one. " }, { "title": "Homelab series - Bootstrap", "url": "/posts/homelab/", "categories": "howto, homelab", "tags": "ansible, docker, portainer", "date": "2024-09-30 02:11:00 -0600", "snippet": "Homelab Series - BootstrapObjectives for this Homelab Series: Lay out an easy to follow guide to setup a homelab, with repeatable and scripted actions where possible. The homelab repo on github will contain all the good bits.Prerequisites You have a server, virtual machine, LXC container, or the like, with SSH access. The system should be running Debian, similar OS may work with small changes.Action Plan Setup Ansible either directly on the server, or on your desktop using the bootstrap script. You need to be running a Linux desktop and have SSH keys copied to the server if putting Ansible on the desktop. Otherwise you can run the bootstrap script on the server itself. From the same directory as the bootstrap script was ran, activate the ansible environment source env/bin/activate Edit the ansible/hosts file to add the server IP(s), see example proxmox, or use desktops group for local. Run the Debian playbook for the base configuration changes note: limit in this case will run it on your local host. cd homelabansible-playbook run_debian_template.yml --limit=desktops Next lets install docker and portainer on the homelab server. In this case we just install it locally on one machine, but if you put a list or range of IPs in hosts earlier, all of them will be setup as part of your homelab. ansible-playbook run_docker.yml --limit=desktops What to read next? How about this article to get started filling docker up with useful containers? Portainer Deployments UPDATE: The homelab repo has an additional role to deploy minecraft, replacing the need for this previous repository. " }, { "title": "Rainbow Queries for little data", "url": "/posts/rainbow_query/", "categories": "data", "tags": "VScode, rainbowCSV", "date": "2024-06-12 14:00:00 -0600", "snippet": "Rainbow CSV with queriesMy tool of choice for big-but-not-too-big text files that need viewing and maybe a bit of filtering is Rainbow CSV extension in VS Code. This works well as long as the file isn’t over the 20-40MB threshold where VScode no longer wants to load it. Once we are working with files that size, Python Pandas seems to fit the requirements.Similiar to the example done for Pandas, slicing down the data by a simple condition is just as easy. Running this will create a new file with just the results.More to come, all the other sql like things you can do." }, { "title": "Python Pandas for big data", "url": "/posts/big_data/", "categories": "data", "tags": "pandas, python", "date": "2024-06-12 10:00:00 -0600", "snippet": "Pandas vs Rainbow Query LanguageMy tool of choice for “big” text files that need viewing and maybe a bit of filtering is Rainbow CSV extension in VS Code, and writing some quick queries with its built in language. However when the files get truly massive, Rainbow and VS Code gives up, so I had to learn enough Pandas to work on the files there, or break it down to something I can use with Rainbow. I believe this threshold for what is too big is currently in the 20-40MB range.These are my notes on using python Pandas to analyze or edit large (100MB+) files. ALso available is a post on often used Rainbow queries.Jupyter notebook loading a dataframe.Viewing the first few rows, to determine column name and value to split on.Split the large dataset down to just the details to analyze further." }, { "title": "Portainer Deployment options", "url": "/posts/portainer-deployment/", "categories": "howto", "tags": "portainer, docker, ansible", "date": "2023-01-16 02:11:00 -0600", "snippet": "Portainer Deployment OptionsTwo different approaches on how to deploy Portainer, and Docker containers within Portainer.Option 1: AnsibleI’m a big fan of ansible, and try to build all my infrastructure, configuration and maintenance tasks with it. You can read about Ansible on the documentation site. Or watch a great series on youtube at Jeff Greeling.I created a repository that lets someone with no ansible experience bootstrap the installation, and then run a playbook (automated tasks) to install Docker, Portainer, and a Minecraft container. It’s a fun way to get started with Ansible and Portainer. Ansible Portainer DeploymentOption 2: Github referenced Portainer compose filesThis option is fairly simple, in that you are just storing your docker-compose files on github, and pointing Portainer to the repository.You can tell Portainer to watch the repository for changes, and restart containers as the compose files change, or you can leave it manual, and restartcontainers only if you want the new configuration taken. Portainer Github repository" }, { "title": "Keepalive Configurations", "url": "/posts/keepalived/", "categories": "howto, homelab", "tags": "keepalived", "date": "2023-01-12 05:30:00 -0600", "snippet": "Keepalive ConfigurationsKeepalive installsudo apt install keepalived libipset13Configuration for High AvailabilityConfiguration should be done on the two nodes, setting one as master and one as backup. Master will serve traffic unless unavailable, at which time the backup node will take over serving traffic until master is available again.Master Configuration# /etc/keepalived/keepalived.conf# Keepalive configuration for Master nodevrrp_instance DNS { state MASTER interface eth0 virtual_router_id 55 # Must match backup priority 150 # Higher than backup advert_int 1 unicast_src_ip 192.168.0.10 unicast_peer { 192.168.0.11 } authentication { auth_type PASS auth_pass password # Use same on backup } virtual_ipaddress { 192.168.0.100/24 }}Backup Configuration# /etc/keepalived/keepalived.conf# Keepalive configuration for backup nodevrrp_instance DNS { state BACKUP interface eth0 virtual_router_id 55 priority 100 advert_int 1 unicast_src_ip 192.168.0.11 unicast_peer { 192.168.0.10 } authentication { auth_type PASS auth_pass password } virtual_ipaddress { 192.168.0.100/24 }}Configuration as load balancer.Alternatively to being used for high availability, keepalive can also be configured as a load balancer using the below configuration. Additionally, both HA and load balance can be combined, however that configuration is not covered here.# /etc/keepalived/keepalived.conf# Load Balancer nodevrrp_instance LB1 { state MASTER interface eth0 virtual_router_id 51 priority 100 virtual_ipaddress { 192.168.0.100 }}virtual_server 192.168.0.100 80 { delay_loop 6 lb_algo rr lb_kind NAT protocol TCP real_server 192.168.0.10 80 { weight 100 TCP_CHECK { connect_timeout 3 } } real_server 192.168.0.11 80 { weight 100 TCP_CHECK { connect_timeout 3 } }}" }, { "title": "Restore from a Mirror", "url": "/posts/restore-mirror/", "categories": "howto", "tags": "git", "date": "2022-09-20 15:00:00 -0600", "snippet": "Restore Repository using a Git MirrorIf you followed the guide on setting up a mirror as a real-time backup, you may now be wondering how can I restore a lost or corrupt repository using the mirror. For this how-to we will use Github (source) as the mirror and Gitlab (destination) as the repository to restore. Please Note: this method assumes whatever corrupted the source repository was not also mirrored, if that is the case, snapshots or backups are what you will want.Option 1 Copy the clone URL for the mirror - git@github.com:Sarlaac/sandbox-mirror.git Clone the copy to a temporary local repositorygit clone git@github.com:Sarlaac/sandbox-mirror.git Update the remote URL to the repository you want to restore.git remote set-url &amp;lt;name&amp;gt; &amp;lt;newurl&amp;gt; [&amp;lt;oldurl&amp;gt;]git remote set-url origin git@gitlab.com:sarlaac/sandbox-demo.git git@github.com:Sarlaac/sandbox-mirror.git Check that the new URL is in place.git remote -v Push the local copy to Gitlab, restoring the repository. You may need to force-push depending on the state of the destination." }, { "title": "Mirror a Gitlab repository to Github", "url": "/posts/gitlab-mirror/", "categories": "howto", "tags": "git", "date": "2022-09-20 09:00:00 -0600", "snippet": "Mirror a Gitlab repository to GithubGit repository mirrors can be useful to create a real-time copy of a repository for backup purposes, or as a transitional step when moving from one git platform to another. In this post we will walk through creating a mirror from a Gitlab repository to create a Github repository.To start off create a new empty repository in Github. Do not add a readme or any other files. Copy the SSH clone URL - git@github.com:Sarlaac/sandbox-mirror.git Update the URL to add ssh:// and change the colon after github.comssh://git@github.com/Sarlaac/sandbox-mirror.gitNow let’s logon to Gitlab and go to the repository you want to mirror. In the repository, go to Settings &amp;gt; Repository &amp;gt; Mirroring repositories Enter the URL we created earlier. Click on detect host keys Switch from password to SSH public key Click on the Mirror repository button.There should be an entry under Mirrored Repositories Copy the SSH public key.Back on Github, go to the repositories settings. Add the key as a deploy key. Be sure to check the allow write access.That’s it! Test the setup by committing a change on the Gitlab repository and go look for it to be mirrored to the Github repository. If you are interested in how this mirror can be used to restore a corrupt or lost repository I have a post for that now." } ]
